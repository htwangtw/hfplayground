{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting atlas shipped in BrainLM\n",
    "\n",
    "The original data processing code of BrainLM extract time sereis using A424 atlas in an unidentified MNI152 template in 2mm space. \n",
    "\n",
    "There were no sainty check to make sure all the functional data and the atlas are in the same space.\n",
    "Hence for the purpose of running the BrainLM tutorial using the nilearn test dataset developmental dataset, and using as much of the original code as possible, we need to manually resample the atlas to match the nilearn developmental dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting, image\n",
    "import nibabel as nib\n",
    "from nilearn.maskers import NiftiLabelsMasker, NiftiSpheresMasker, NiftiMasker, NiftiMapsMasker\n",
    "from nilearn.datasets import MNI152_FILE_PATH, load_mni152_gm_mask, fetch_atlas_difumo\n",
    "from importlib.resources import files\n",
    "import numpy as np\n",
    "from hfplayground.data import downsample_for_tutorial\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_from_disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_atlas = downsample_for_tutorial(files('hfplayground') / 'data/brainlm/atlases/A424+2mm.nii.gz', '/tmp/')\n",
    "downsample_mni = downsample_for_tutorial(MNI152_FILE_PATH, '/tmp/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original A424 atlas is very strictly following the grey matter, and includes the cerebellum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(files('hfplayground') / 'data/brainlm/atlases/A424+2mm.nii.gz', title=\"Original A424 atlas\", black_bg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nilearn test dataset has been downsampled to voxel size 4mm^3, so we have to resample the atlas accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(downsample_atlas, downsample_mni, title=\"Resampled A424 atlas for tutorial purpose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay it on real data. \n",
    "\n",
    "We can see that the cerebellum is cut off in the EPI scan. This is a very common compromise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_img = image.load_img('../data/external/development_fmri/development_fmri/sub-pixar124_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')\n",
    "plotting.plot_roi(downsample_atlas, bg_img=bg_img.slicer[..., 0], title=\"Resampled A424 atlas overlay on fMRIprep preprocessed data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlaying on data after denoising. Since I used a MNI template brain mask, we can see the missing cerebellum is filled up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_img = image.load_img('../data/interim/development_fmri/sub-pixar124_task-pixar_space-MNI152NLin2009cAsym_desc-simple+gsr_bold.nii.gz')\n",
    "plotting.plot_roi(downsample_atlas, bg_img=bg_img.slicer[..., 0], title=\"Resampled A424 atlas overlay on fMRIprep preprocessed + denoised data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have some preprocessed time series, using their workflow, let's have a look at the results.\n",
    "\n",
    "The fMRIPrep data here is preprocessed with FWHM 8mm, standardization at per voxel level, and denoise with the simple strategy of load_confounds, with cosine regressors, 6 motion parameters, white matter/csf followed by some very sus workflow provided with the code to extract time sereis from the ROIs.\n",
    "\n",
    "These outputs are hugging face / arrow datasets. For the brain region coordinates, each entry is a brain region with it's index, and corrdinate of the centroid.\n",
    "\n",
    "For the time series data, each subject is an entry:\n",
    "- Raw_Recording: number of ROI, number of time points\n",
    "- Voxelwise_RobustScaler_Normalized_Recording: number of time points, number of ROI\n",
    "- All_Patient_All_Voxel_Normalized_Recording: number of ROI, number of time points\n",
    "- Per_Patient_All_Voxel_Normalized_Recording: number of ROI, number of time points\n",
    "- Per_Patient_Per_Voxel_Normalized_Recording: number of ROI, number of time points\n",
    "- Per_Voxel_All_Patient_Normalized_Recording: number of ROI, number of time points\n",
    "- Subtract_Mean_Normalized_Recording: number of ROI, number of time points \n",
    "- Subtract_Mean_Divide_Global_STD_Normalized_Recording: number of ROI, number of time points \n",
    "- Subtract_Mean_Divide_Global_99thPercent_Normalized_Recording: number of ROI, number of time points \n",
    "- Filename: just file name\n",
    "- Patient ID: totally failed at parsing this, no value\n",
    "\n",
    "I am going to use seed base connectivity using the PCC as a way to do some sanity check.\n",
    "With a quick search in the script, it seems there are multiple scaling strategy that has been tested at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually found a PCC ish coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_ds = load_from_disk(\"../data/processed/development_fmri_brainlm_a424/brainregion_coordinates.arrow\")\n",
    "\n",
    "roi_index = 215  # this is index saved in file, so 1-based\n",
    "coord = [int(coords_ds[roi_index - 1][k]) for i, k in enumerate(coords_ds[roi_index - 1]) if i != 0]\n",
    "plotting.plot_roi(\n",
    "    downsample_atlas, \n",
    "    bg_img=downsample_mni, \n",
    "    title=f\"ROI index {coords_ds[roi_index - 1]['Index']}, coordinate is {coord}\", \n",
    "    cut_coords=coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create seed base connectivity map as a base of comparison for all scaled data by BrainLM workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_seed = NiftiSpheresMasker(seeds=[coord], radius=8).fit()\n",
    "mni_mask = nib.save(load_mni152_gm_mask(), Path('/tmp/mni_mask.nii.gz'))\n",
    "mni_mask = downsample_for_tutorial(Path('/tmp/mni_mask.nii.gz'), '/tmp/')\n",
    "mni_masker = NiftiMasker(mni_mask, target_affine=bg_img.affine, target_shape=bg_img.shape[:3]).fit()\n",
    "\n",
    "filename = 'sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-simple+gsr_bold.nii.gz'\n",
    "nii_path = f\"../data/interim/development_fmri/{filename}\"\n",
    "ts = get_seed.transform(nii_path)\n",
    "voxels = mni_masker.transform(nii_path)\n",
    "seed_base_connectivity = np.corrcoef(ts.T, voxels.T)[1:, 0]\n",
    "seed_base_nii = mni_masker.inverse_transform(seed_base_connectivity)\n",
    "\n",
    "plotting.plot_stat_map(seed_base_nii, \n",
    "    threshold=0.01, cut_coords=coord, bg_img=downsample_mni, \n",
    "    black_bg=True, colorbar=True,\n",
    "    title=f\"Seed based: ROI {roi_index}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also use DiFuMo to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difumo_pcc = 142\n",
    "difumo_masker = NiftiMapsMasker(fetch_atlas_difumo(dimension=512, resolution_mm=3).maps)\n",
    "difumo_ts = difumo_masker.fit_transform(nii_path)\n",
    "seed_base_connectivity = np.corrcoef(difumo_ts.T)[difumo_pcc - 1]\n",
    "nii = difumo_masker.inverse_transform(seed_base_connectivity)\n",
    "plotting.plot_stat_map(\n",
    "    nii, vmin=-0.002, vmax=0.002, colorbar=True,\n",
    "    cut_coords=coord,\n",
    "    title=f\"Difumo 512 atlas, PCC index {difumo_pcc} connectivity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_masker = NiftiLabelsMasker(files('hfplayground') / 'data/development_fmri/downsample_A424+4mm.nii.gz').fit()\n",
    "\n",
    "arrow_path = Path(\"../data/processed/development_fmri_brainlm_a424/fmri_development.arrow\")\n",
    "ds = load_from_disk(arrow_path)\n",
    "prepro_method = arrow_path.name.split(\"development_fmri_\")[-1].split(\"_a424\")[0]\n",
    "for i, subject in enumerate(ds):\n",
    "    if \"sub-123_\" in subject['Filename']:\n",
    "        break\n",
    "for key in ['Voxelwise_RobustScaler_Normalized_Recording', 'Raw_Recording']:\n",
    "    if \"Recording\" not in key:\n",
    "        continue\n",
    "    if key == 'Voxelwise_RobustScaler_Normalized_Recording':\n",
    "        seed_base_connectivity = np.corrcoef(np.array(ds[i][key]).T)[roi_index - 1]\n",
    "    else:\n",
    "        seed_base_connectivity = np.corrcoef(np.array(ds[i][key]))[roi_index - 1]\n",
    "    nii = atlas_masker.inverse_transform(seed_base_connectivity)\n",
    "    plotting.plot_stat_map(\n",
    "        nii, vmin=-0.5, vmax=0.5, threshold=0.01,  colorbar=True,\n",
    "        cut_coords=coord, bg_img=downsample_mni,\n",
    "        title=f\"{key} {prepro_method} : ROI {roi_index}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arrow_path = Path(\"../data/processed/development_fmri_gigaconnectome_a424/fmri_development.arrow\")\n",
    "ds = load_from_disk(arrow_path)\n",
    "prepro_method = arrow_path.name.split(\"development_fmri_\")[-1].split(\"_a424\")[0]\n",
    "for i, subject in enumerate(ds):\n",
    "    if \"sub-123\" == subject['participant_id']:\n",
    "        break\n",
    "for key in ds[i].keys():\n",
    "    if \"timeseries\" not in key:\n",
    "        continue\n",
    "    seed_base_connectivity = np.corrcoef(np.array(ds[i][key]).T)[roi_index - 1, :]\n",
    "    nii = atlas_masker.inverse_transform(seed_base_connectivity)\n",
    "    plotting.plot_stat_map(\n",
    "        nii, vmin=-0.5, vmax=0.5, threshold=0.01, colorbar=True,\n",
    "        cut_coords=coord, bg_img=downsample_mni,\n",
    "        title=f\"{key} {prepro_method} : ROI {roi_index}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The various scaling done in the BrainLM workflow will produce drasically different results if the preprocessed data did not have any kind of scaling per voxel.\n",
    "It is unclear why they still tested so many different approaches as in the documentation it seems they did apply normalisation (assuming this is normalisation per voxel) in the UKBB data (the training data for the pretrain model.)\n",
    "\n",
    "We can use the giga connectome output without the scaling workflow safely.\n",
    "\n",
    "In BrainLM workflow, they replace nan in timeseries with 0.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
